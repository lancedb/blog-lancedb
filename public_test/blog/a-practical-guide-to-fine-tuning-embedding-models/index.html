<!doctype html><html lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>A Practical Guide to Fine-Tuning Embedding Models - LanceDB Blog</title><link rel=stylesheet href=/css/custom.css><link rel=stylesheet href=/css/syntax-highlighting.css><script src=/js/toc-progress.js></script><script src=/js/heading-links.js></script><script src=/js/announcement.js></script><script src=/js/code-blocks.js></script></head><body><div class=announcement-bar id=announcement-bar><div class=announcement-content><span>June 1st, 2025: LanceDB Cloud is now in public beta!</span>
<a href=https://lancedb.com/cloud class=announcement-link>Try it now →</a>
<button class=announcement-close onclick=closeAnnouncement()>×</button></div></div><header class=site-header><div class=header-content><a href=/ class=site-title><img src=/assets/blog/logo.png alt="LanceDB Blog" class=site-logo></a><div class=header-links><a href=/docs class=header-link>Documentation</a>
<a href=/pricing class=header-link>Pricing</a>
<a href=/get-started class="header-link get-started">Get Started</a></div></div></header><div class=content-wrapper><div class=toc-container><div class=toc><h2>Table of Contents</h2><nav id=TableOfContents><ul><li><a href=#tuning-embedding-models>Tuning Embedding Models</a><ul><li><a href=#fine-tuning-results>Fine-tuning Results</a></li><li><a href=#should-you-always-fine-tune-embedding-models>Should You Always Fine-tune Embedding Models?</a></li><li><a href=#squad-fine-tuning-results>SQuAD Fine-tuning Results</a></li><li><a href=#fine-tuned-embedder--reranker>Fine-tuned Embedder + Reranker?</a></li></ul></li><li><a href=#using-embedding-functions-with-lancedb>Using Embedding Functions with LanceDB</a></li><li><a href=#reproducibility>Reproducibility</a></li></ul></nav></div></div><main><h1>A Practical Guide to Fine-Tuning Embedding Models</h1><div class=post-meta><span class=post-category>Engineering</span>
<span class=meta-divider>•</span>
<span class=post-author>Ayush Chaurasia</span>
<span class=meta-divider>•</span>
<span class=post-date>March 25, 2024</span></div><article class=single-post><img src=/assets/blog/a-practical-guide-to-fine-tuning-embedding-models/a-practical-guide-to-fine-tuning-embedding-models.png alt="A Practical Guide to Fine-Tuning Embedding Models" class=preview-image><div class=post-content><p>This is a follow up to the following report that deals with improving retrievers by training and fine-tuning reranker models</p><p><a href=/a-practical-guide-to-training-custom-rerankers/>A Practical Guide to Training Custom Rerankers</a></p><p>In this report, we try to answer questions like - <em>If/when should you fine-tune embedding models, and what are the qualities of a good fine-tuning dataset</em></p><p>We&rsquo;ll deal with embedding part of the retrieval pipeline, which means any changes or updates will require re-ingestion of the data, unlike reranking.</p><p><img src=/assets/blog/a-practical-guide-to-fine-tuning-embedding-models/Screenshot-2025-04-20-at-7.49.44-PM.png alt="Retrieval Pipeline"></p><h2 id=tuning-embedding-models>Tuning Embedding Models</h2><p>For this report, the sentence-transformers Python library used to fine-tune embedding models, the same as the previous reranking report.</p><p><img src=/assets/blog/a-practical-guide-to-fine-tuning-embedding-models/Screenshot-2025-04-19-at-9.45.35-PM.png alt="Sentence Transformers"></p><p>You can refer to the guide to fine-tuning and training embedding models using sentence-transformers <a href=https://huggingface.co/blog/train-sentence-transformers>here</a>. In brief, the training process happens in the following steps:</p><ul><li>Choose a dataset. We&rsquo;re using GooQA dataset&rsquo;s <code>question</code> and <code>context</code> columns</li><li>Mine hard negatives to transform it into a similarity dataset of triplets formats (anchor, positive, negative)</li><li>Repeat the same process for evaluation set</li><li>Choose a loss function for your dataset format. Here we&rsquo;ll use <code>MultipleNegativesLoss</code></li><li>Choose a suitable evaluator based on your dataset format. Here we&rsquo;ll use <code>TripletEvaluator</code></li><li>Finally, run the training loop for the desired iterations/epochs.</li></ul><p><strong>Base model -</strong> The base model used is <code>all-MiniLM-L6-v2</code> as it was the model used for embedding generation in the Rerankers report as well.</p><h3 id=fine-tuning-results>Fine-tuning Results</h3><p>Here are the results of fine-tuning the model as described in the previous section.</p><p><strong>Hit rate @5</strong></p><p><img src=/assets/blog/a-practical-guide-to-fine-tuning-embedding-models/Screenshot-2025-04-16-at-7.22.41-PM.png alt="Hit Rate @5"></p><p><strong>Hit rate @10</strong></p><p><img src=/assets/blog/a-practical-guide-to-fine-tuning-embedding-models/Screenshot-2025-04-16-at-7.23.28-PM.png alt="Hit Rate @10"></p><ul><li>Overall, we see improvements of <strong>roughly 10% across both top 5 and top 10</strong></li><li>The main thing to notice here is that <strong>each fine-tuned model performs significantly better than the baseline</strong></li><li>Increasing the number of iterations generally tends to improve the results further, which is expected.</li><li>Towards the end, where the model is trained for larger epochs (10), it starts to show some signs of unstable training or overfitting, which, again, is expected.</li></ul><h3 id=should-you-always-fine-tune-embedding-models>Should You Always Fine-tune Embedding Models?</h3><p>The most important question at this point is if we can generalize these results, i.e, <strong>should you always fine-tune your embedding models if you can?</strong></p><p>Fine-tuning is like training. The only difference is that when training a model, you start with random or close-to-random weights that output gibberish. When fine-tuning, you start with a model already trained on some different dataset or combination of datasets.</p><p>Let&rsquo;s look at another example.</p><p><strong>Experiment setup</strong></p><ul><li>Model - all-MiniLM-L6-v2 ( same as before)</li><li>Dataset - SQuAD. The dataset has ~90K rows. For this experiment, I used 45K rows for the training set and 5K for the evaluation set. The format and loss functions used were the same as the ones used in GooQA dataset fine-tuning.</li><li>In contrast to previous experiment, the dataset is much smaller (2M rows vs 45K rows)</li></ul><p><strong>Ideal scenario for fine-tuning</strong></p><p>Another thing to note about the dataset is that both of these datasets are general QA datasets, i.e., they&rsquo;re not specialized domain-specific query-context pairs. SQuAD is a popular dataset that most embedding models use as a part of their larger training set.</p><p>Here&rsquo;s the visualization of the training dataset and fine-tuning dataset.</p><p><img src=/assets/blog/a-practical-guide-to-fine-tuning-embedding-models/Screenshot-2025-04-17-at-2.59.17-PM.png alt="Training Dataset Visualization"></p><p>An educated guess would be to associate fine-tuning on</p><ul><li><p>SQuAD dataset as the left representation.</p></li><li><p>In this case, <strong>you&rsquo;re fine-tuning the model on the subset of data it has already seen</strong> without adding any new information.</p></li><li><p>This can result in unstable training, overfitting, catastrophic forgetting or just some sudden performance degradation depending on the training process</p></li><li><p>It is <strong>generally not recommended to fine-tune</strong> in such scenarios. Evaluation <strong>might initially show good results due to overfitting</strong>.</p></li><li><p>A large domain-specific dataset as the right representation.</p></li><li><p>You can think of legal docs or financial reports/filings, etc., as a large domain-specific corpus that might have a small intersection with the larger general training data.</p></li><li><p><strong>It is recommended to fine-tune models on such datasets</strong> as it allows the model to adapt to a new domain, specializing in answering those questions with better context or more confidence.</p></li><li><p>GooQA dataset as somewhere between the left and the right representation.</p></li><li><p>GooQA is much larger than SQuAD, yet it is a general QA dataset without any domain specifications.</p></li><li><p>Training on this dataset should be much more stable than SQuAD, <strong>and you can fine-tune on such datasets if you expect future user queries to be limited to the same distribution</strong>. In the real world, the chance of this happening is quite low.</p></li></ul><h3 id=squad-fine-tuning-results>SQuAD Fine-tuning Results</h3><p>Here&rsquo;s what happens if you fine-tune on a dataset that&rsquo;s similar to the representation on the left</p><p><strong>hit rate @5</strong></p><p><img src=/assets/blog/a-practical-guide-to-fine-tuning-embedding-models/Screenshot-2025-04-20-at-7.09.35-PM.png alt="SQuAD Hit Rate @5"></p><p><strong>Hit rate @ 10</strong></p><p><img src=/assets/blog/a-practical-guide-to-fine-tuning-embedding-models/Screenshot-2025-04-20-at-7.10.18-PM.png alt="SQuAD Hit Rate @10"></p><p>The results seem aligned with our analysis in the previous section:</p><ul><li>The delta in improvement is much smaller.</li><li><strong>The model starts to overfit much faster</strong>. In fact, in most cases with a high number of epochs, the results get worse. In the case of hit-rate@10, only 3 models perform better than the baseline.</li></ul><p>Let&rsquo;s run another experiment that fine-tunes a much larger model on this dataset, to confirm our hypothesis. Here&rsquo;s the top@5 and top@10 hit-rates on both <code>All-miniLM-L6-v2</code> and <code>bge-1.5-en-base</code> with all results sorted for easier comparison</p><p><img src=/assets/blog/a-practical-guide-to-fine-tuning-embedding-models/Screenshot-2025-04-20-at-7.14.51-PM.png alt="Model Comparison"></p><p>The results** in both experiments seem aligned. Both models overfit at higher epochs, and training is pretty unstable.**</p><p><strong>What about augmentation and synthetic data generation?</strong></p><p>LLMs have lately been used to generate synthetic questions and answers from a given passage/context to fine-tune embedding models. Can&rsquo;t we just use those techniques to augment the dataset in this scenario?</p><p>There are 2 major things to keep in mind before attempting synthetic data generation.</p><ul><li>Augmentation improves the dataset by creating slightly different versions of existing data points. It doesn&rsquo;t necessarily add a lot of <em>new</em> context to your dataset distribution. For example, when training vision models, data augmentation takes an image and randomly crops parts of it or rotates it by certain angles to create new samples. It basically prevents the model from overfitting to a specific angle, position, etc. It doesn&rsquo;t really add any new information about a new class object. So, the rule of thumb to follow in data augmentation is: <strong>Bad data, on augmentation, will most likely result in bad or worse augmented data.</strong></li><li><strong>LLMs hallucinate.</strong> When generating synthetic datasets (questions from context) from existing dataset, it has been found that a large portion of generated questions can be hallucinations or simply of bad quality questions. In fact, there are many tools that are used to filter out hallucinations from the synthetic data generation process.</li></ul><p>So although you can experiment with synthetic data generation, and it also is a very powerful tool to augment good quality datasets, it is not a magical solution if you don&rsquo;t have a decent base dataset.</p><p><img src=/assets/blog/a-practical-guide-to-fine-tuning-embedding-models/Screenshot-2025-04-20-at-7.40.07-PM.png alt="Synthetic Data Generation"></p><h3 id=fine-tuned-embedder--reranker>Fine-tuned Embedder + Reranker?</h3><p>Now coming back to the GooQA dataset experiment results. We saw significant improvement in the results even though the dataset was pretty general, which isn&rsquo;t the best case for fine-tuning. But can we do better? Let&rsquo;s revisit our experiment results from the previous report that dealt with training and fine-tuning reranker models. Here&rsquo;s the best result that we got after fine-tuning an existing reranker.</p><p><img src=/assets/blog/a-practical-guide-to-fine-tuning-embedding-models/image-5.png alt="Reranker Results"></p><p>The <strong>best results were 70% @top10 and 62.35% @top5</strong> respectively</p><p>You can read the entire report here for more details on reranking process and tradeoffs:</p><p><a href=/a-practical-guide-to-training-custom-rerankers/>A Practical Guide to Training Custom Rerankers</a></p><p>Can we improve the results further by combining our fine-tuned embedding models with the best rerankers @top 5 and top 10? Here are the results (FTS column is irrelevant as FTS doesn&rsquo;t involve embedding models)</p><p><img src=/assets/blog/a-practical-guide-to-fine-tuning-embedding-models/Screenshot-2025-04-16-at-7.25.46-PM.png alt="Combined Results @5"></p><p><img src=/assets/blog/a-practical-guide-to-fine-tuning-embedding-models/Screenshot-2025-04-16-at-7.26.06-PM.png alt="Combined Results @10"></p><p>On combining fine-tuning with reranking, we get new best results:</p><p><img src=/assets/blog/a-practical-guide-to-fine-tuning-embedding-models/Screenshot-2025-04-23-at-2.27.51-PM.png alt="Best Combined Results"></p><p>Top 5 -** 62.34 -> 64.50**</p><p>Top 10 - <strong>70.00 -> 71.85</strong></p><h2 id=using-embedding-functions-with-lancedb>Using Embedding Functions with LanceDB</h2><p>LanceDB has integrations with all popular embedding model providers. With the embedding API, you can simply define the embedding model of your choice when initializing the table, and it&rsquo;ll automatically take care of generating embeddings for both source and queries. Here&rsquo;s an example</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>lancedb</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>lancedb.embeddings</span> <span class=kn>import</span> <span class=n>get_registry</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>lancedb.pydantic</span> <span class=kn>import</span> <span class=n>LanceModel</span><span class=p>,</span> <span class=n>Vector</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>get_registry</span><span class=p>()</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;sentence-transformers&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>create</span><span class=p>()</span> <span class=c1># use default ST model</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># define schema with embedding API</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>Schema</span><span class=p>(</span><span class=n>LanceModel</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>SourceField</span><span class=p>()</span> <span class=c1># All entries of sourcefield are vectorized</span>
</span></span><span class=line><span class=cl>    <span class=n>vector</span><span class=p>:</span> <span class=n>Vector</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>ndims</span><span class=p>())</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>VectorField</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>db</span> <span class=o>=</span> <span class=n>lancedb</span><span class=o>.</span><span class=n>connect</span><span class=p>(</span><span class=s2>&#34;~/lancedb&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>table</span> <span class=o>=</span> <span class=n>db</span><span class=o>.</span><span class=n>create_table</span><span class=p>(</span><span class=n>schema</span><span class=o>=</span><span class=n>Schema</span><span class=p>,</span> <span class=n>name</span><span class=o>=</span><span class=s2>&#34;tbl&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>table</span><span class=o>.</span><span class=n>add</span><span class=p>(</span>
</span></span><span class=line><span class=cl> <span class=p>[</span>
</span></span><span class=line><span class=cl>  <span class=p>{</span><span class=s2>&#34;text&#34;</span><span class=p>:</span> <span class=s2>&#34;some random text&#34;</span><span class=p>},</span>
</span></span><span class=line><span class=cl>  <span class=p>{</span><span class=s2>&#34;text&#34;</span><span class=p>:</span> <span class=s2>&#34;some random text again&#34;</span><span class=p>}</span>
</span></span><span class=line><span class=cl> <span class=p>]</span>
</span></span><span class=line><span class=cl> <span class=p>)</span> <span class=c1># Source field automatically gets converted to their vector embeddings</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>table</span><span class=o>.</span><span class=n>search</span><span class=p>(</span><span class=s2>&#34;search text&#34;</span><span class=p>)</span> 
</span></span><span class=line><span class=cl><span class=c1># You can directly pass string as it&#39;ll be </span>
</span></span><span class=line><span class=cl><span class=c1># converted to embeddings as we&#39;ve initialized </span>
</span></span><span class=line><span class=cl><span class=c1># the schema with embedding API</span>
</span></span></code></pre></div><p>Using a custom fine-tuned embeddings is as simple as passing the model name when initializing model from embedding registry</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>tuned_model</span> <span class=o>=</span> <span class=n>get_registry</span><span class=p>()</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;sentence-transformers&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>create</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                                <span class=n>name</span><span class=o>=</span><span class=s2>&#34;path/to/tuned_model&#34;</span><span class=p>)</span>
</span></span></code></pre></div><h2 id=reproducibility>Reproducibility</h2><p>All code to reproduce the above experiments are available <a href=https://github.com/lancedb/research/tree/main/embedding-fine-tuning>here</a></p><p>All trained models used in this experiment are available of <a href=https://huggingface.co/ayushexel>HF hub</a></p></div></article><div class=author-section><img src=/assets/authors/ayush-chaurasia.jpg alt="Ayush Chaurasia" class=author-avatar><div class=author-info><h3 class=author-name>Ayush Chaurasia</h3><p class=author-bio>ML Engineer and researcher focused on multi-modal AI systems and efficient retrieval methods.</p><div class=author-social><a href=https://twitter.com/ayushchaurasia target=_blank rel=noopener><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M23 3a10.9 10.9.0 01-3.14 1.53 4.48 4.48.0 00-7.86 3v1A10.66 10.66.0 013 4s-4 9 5 13a11.64 11.64.0 01-7 2c9 5 20 0 20-11.5a4.5 4.5.0 00-.08-.83A7.72 7.72.0 0023 3z"/></svg>
Twitter
</a><a href=https://github.com/ayushchaurasia target=_blank rel=noopener><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg>
GitHub
</a><a href=https://linkedin.com/in/ayushchaurasia target=_blank rel=noopener><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M16 8a6 6 0 016 6v7h-4v-7a2 2 0 00-2-2 2 2 0 00-2 2v7h-4v-7a6 6 0 016-6z"/><rect x="2" y="9" width="4" height="12"/><circle cx="4" cy="4" r="2"/></svg>
LinkedIn</a></div></div></div><div class=related-posts><h2>Related Posts</h2><div class=related-posts-grid><article class=related-post><a href=/blog/columnar-file-readers-in-depth-repetition-definition-levels/><img src=/assets/blog/columnar-file-readers-in-depth-repetition-definition-levels/columnar-file-readers-in-depth-repetition-definition-levels.png alt="Columnar File Readers in Depth: Repetition & Definition Levels" class=related-preview-image></a><h3><a href=/blog/columnar-file-readers-in-depth-repetition-definition-levels/>Columnar File Readers in Depth: Repetition & Definition Levels</a></h3><div class=post-meta><span class=post-author>Weston Pace</span>
<span class=post-date>June 2, 2025</span></div></article><article class=related-post><a href=/blog/columnar-file-readers-in-depth-column-shredding/><img src=/assets/blog/columnar-file-readers-in-depth-column-shredding/columnar-file-readers-in-depth-column-shredding.png alt="Columnar File Readers in Depth: Column Shredding" class=related-preview-image></a><h3><a href=/blog/columnar-file-readers-in-depth-column-shredding/>Columnar File Readers in Depth: Column Shredding</a></h3><div class=post-meta><span class=post-author>Weston Pace</span>
<span class=post-date>May 15, 2025</span></div></article><article class=related-post><a href=/blog/columnar-file-readers-in-depth-compression-transparency/><img src=/assets/blog/columnar-file-readers-in-depth-compression-transparency/columnar-file-readers-in-depth-compression-transparency.png alt="Columnar File Readers in Depth: Compression Transparency" class=related-preview-image></a><h3><a href=/blog/columnar-file-readers-in-depth-compression-transparency/>Columnar File Readers in Depth: Compression Transparency</a></h3><div class=post-meta><span class=post-author>Weston Pace</span>
<span class=post-date>April 29, 2025</span></div></article></div></div></main></div><footer class=site-footer><div class=footer-content><a href=/ class=site-title><img src=/assets/blog/logo.png alt="LanceDB Blog" class=site-logo></a><div class=footer-links><a href=https://lancedb.com/documentation class=footer-link>Documentation</a>
<a href=https://lancedb.com/pricing class=footer-link>Pricing</a>
<a href=/get-started class="footer-link get-started">Get Started</a></div></div></footer></body></html>