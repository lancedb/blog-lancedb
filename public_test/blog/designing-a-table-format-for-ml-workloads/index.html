<!doctype html><html lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Designing a Table Format for ML Workloads - LanceDB Blog</title><link rel=stylesheet href=/css/custom.css><link rel=stylesheet href=/css/syntax-highlighting.css><script src=/js/toc-progress.js></script><script src=/js/heading-links.js></script><script src=/js/announcement.js></script><script src=/js/code-blocks.js></script></head><body><div class=announcement-bar id=announcement-bar><div class=announcement-content><span>June 1st, 2025: LanceDB Cloud is now in public beta!</span>
<a href=https://lancedb.com/cloud class=announcement-link>Try it now â†’</a>
<button class=announcement-close onclick=closeAnnouncement()>Ã—</button></div></div><header class=site-header><div class=header-content><a href=/ class=site-title><img src=/assets/blog/logo.png alt="LanceDB Blog" class=site-logo></a><div class=header-links><a href=/docs class=header-link>Documentation</a>
<a href=/pricing class=header-link>Pricing</a>
<a href=/get-started class="header-link get-started">Get Started</a></div></div></header><div class=content-wrapper><div class=toc-container><div class=toc><h2>Table of Contents</h2><nav id=TableOfContents><ul><li><a href=#what-is-a-table-format>What is a Table Format?</a></li><li><a href=#modern-workloads>Modern Workloads</a><ul><li><a href=#the-curse-of-wide-data>The Curse of Wide Data</a></li><li><a href=#tables-grow-horizontally-and-vertically>Tables Grow Horizontally <em>and</em> Vertically</a></li><li><a href=#data-is-messy>Data is Messy</a></li></ul></li><li><a href=#modern-problems-and-some-modern-solutions>Modern Problems (and some modern solutions)</a><ul><li><a href=#data-evolution--schema-evolution>Data Evolution > Schema Evolution</a></li><li><a href=#search-is-everywhere>&ldquo;Search&rdquo; is Everywhere</a></li><li><a href=#the-well-rounded-implementation>The Well Rounded Implementation</a></li></ul></li><li><a href=#whats-next>What&rsquo;s Next</a></li><li><a href=#special-thanks>Special Thanks</a></li></ul></nav></div></div><main><h1>Designing a Table Format for ML Workloads</h1><div class=post-meta><span class=post-category>Engineering</span>
<span class=meta-divider>â€¢</span>
<span class=post-author>Weston Pace</span>
<span class=meta-divider>â€¢</span>
<span class=post-date>March 25, 2024</span></div><article class=single-post><img src=/assets/blog/designing-a-table-format-for-ml-workloads/designing-a-table-format-for-ml-workloads.png alt="Designing a Table Format for ML Workloads" class=preview-image><div class=post-content><p>In recent years the concept of a <strong>table format</strong> has really taken off, with explosive growth in technologies like <a href=https://en.wikipedia.org/wiki/Apache_Iceberg>Iceberg</a>, Delta, and Hudi. With so many great options, one question I hear a lot is variations of &ldquo;why can&rsquo;t Lance use an existing format like &mldr;?&rdquo;</p><p>In this blog post I will describe the Lance table format and hopefully answer that question. The very short TL;DR: <strong>existing table formats don&rsquo;t handle our customer&rsquo;s workflows. Basic operations require too much data copy, are too slow, or cannot be parallelized.</strong></p><h2 id=what-is-a-table-format>What is a Table Format?</h2><p>A table format is probably more accurately thought of as a protocol. It describes how the basic table operations (adding rows, deleting rows, etc.) happen. In other words, it tells us how data files change, what metadata we need to record, what extra structures (e.g. deletion files) are needed, and so on. In the interest of brevity I&rsquo;m not going to fully describe every operation in the Lance table format in this article. A more complete description can be found in <a href=https://lancedb.github.io/lance/format.html>our docs</a>. If you are familiar with Iceberg or Delta, then Lance is not very different. In the following sections I&rsquo;ll focus on what is different.</p><div class="admonition fun-fact inline"><div class=admonition-content><div class=admonition-title>Fun-Fact</div>&ldquo;Table formats stuff the CRUD into file formats&rdquo; is a questionable tagline</div></div><h2 id=modern-workloads>Modern Workloads</h2><p>When I talk about &ldquo;modern workloads&rdquo; I&rsquo;m generally talking about large ML workloads that are developing, training, or using various models. These workloads are not limited to LLMs (there are many types of models) and they can be very diverse. However, we have noticed a few commonalities.</p><h3 id=the-curse-of-wide-data>The Curse of Wide Data</h3><p>As data science gets more sophisticated, scientists are bringing their work to bear on larger and larger data types. Text is moving from &ldquo;simple labels&rdquo; to things like complex prose, websites, and source code. Multi-modal data such as audio, images, and video are being introduced. Even numerical data can get large when we consider items like tensors, vector embeddings, etc.</p><p>As I&rsquo;ve worked with wide data I&rsquo;ve come to an interesting observation that I am going to start referring to as <em>the curse of wide data</em> (because that&rsquo;s a fun sounding name). <strong>If some of your data is wide then most of your data is wide.</strong> One of our team cats has agreed to assist with a demonstration:</p><div class=image-grid><img src=/assets/blog/designing-a-table-format-for-ml-workloads/chunky_lance-1.png alt="Wide Data Demonstration">
<em>Visualizing Data Width: A playful demonstration of how a single wide column can dominate data storage requirements, featuring our team mascot.</em></div><p>If cats are not convincing then we can try a simple example. If you take the TPC-H line items table (the kind of thing all your favorite databases are optimized against) and add a single 3KiB vector embedding column then that table will go from 16 columns to 17 columns&mldr;and will go from 0% wide data to 99% wide data.</p><figure><img src=/assets/blog/designing-a-table-format-for-ml-workloads/TPCH-with-wide.png alt="TPC-H with Wide Data"><figcaption>Data Distribution Analysis: Adding a 3KB vector embedding to the TPC-H line items table shifts the data distribution dramatically, with the embedding consuming 99% of the total storage.</figcaption></figure><h3 id=tables-grow-horizontally-and-vertically>Tables Grow Horizontally <em>and</em> Vertically</h3><p>Your internal model of a database table is probably something that grows mostly <em>longer</em> with time. For example, we have a sales table that gains new rows each time a sale is made at some company. Or maybe we are recording user clicks on some website. Or perhaps our table gains a new row every time a new post about table formats is made.</p><p>Once you put data scientists into the mix, something strange starts to happen. The table starts to grow horizontally, often growing outward from a single column. For example, let&rsquo;s consider a research project that starts by scraping Wikipedia and creating one fat column &ldquo;article text&rdquo; which contains the Wikipedia markup. Then the data scientists get to work. They add a new column, &ldquo;sentiment analysis&rdquo;, that measures if the article has a positive or negative tone. Then they add &ldquo;political bias&rdquo;. Then they go and scrape some more data and add an &ldquo;edit count&rdquo; column. This process repeats and repeats until, in some frightening cases, we can have hundreds or thousands of columns!</p><figure><img src=/assets/blog/designing-a-table-format-for-ml-workloads/growing-in-2d.png alt="Growing in 2D"><figcaption>ML data starts with a core collection of observances. Over time both new observances AND new features are added to the data.</figcaption></figure><p>This process of adding columns repeats again and again as scientists discover new interesting things about the underlying data and make more and more sophisticated observations. Some researchers are now even starting to worry about datasets with <a href=https://arxiv.org/abs/2404.08901>tens of thousands of columns</a> (although we find most users are more in the hundreds-to-thousands scenario).</p><figure><img src=/assets/blog/designing-a-table-format-for-ml-workloads/so-many-features.png alt="Feature Engineering"><figcaption>Feature Engineering Complexity: The exponential growth of feature columns in ML datasets, illustrating how sophisticated analysis can lead to an ever-expanding set of data attributes.</figcaption></figure><h3 id=data-is-messy>Data is Messy</h3><p>This is not a novel observation but it bears repeating. This has many different faces and implications. Cleanup operations (editing, deleting, etc.) are important. Data needs to be searchable so users can understand what they have. Data is often scraped or taken directly from other sources and foreign keys are super common (I can&rsquo;t remember the last customer that <em>didn&rsquo;t</em> have some kind of UUID column). Existing data often needs deduplicated. New data needs to be deduplicated on entry (I sometimes wonder if users are even aware it&rsquo;s possible to add data without using merge). Users need to do a lot of exploration of the data.</p><h2 id=modern-problems-and-some-modern-solutions>Modern Problems (and some modern solutions)</h2><p>I&rsquo;ll now explain the problems we encountered with existing table formats. For each problem I&rsquo;ll explain how we&rsquo;ve solved it in Lance and I&rsquo;ll also make an attempt at explaining some of the alternate solutions we&rsquo;ve seen out there. Let&rsquo;s start with perhaps the most common reason users have given for switching to Lance.</p><h3 id=data-evolution--schema-evolution>Data Evolution > Schema Evolution</h3><p>Table formats offer &ldquo;zero copy schema evolution&rdquo;. This means you can add columns to your table after you&rsquo;ve already added data to your table. This is great but there is one problem and it&rsquo;s in the fine print.</p><figure><img src=/assets/blog/designing-a-table-format-for-ml-workloads/schema-evolution-not-free.png alt="Schema Evolution Fine Print"><figcaption>FREE Schema Evolution (existing rows not included)</figcaption></figure><p>That&rsquo;s right, new columns can only be populated going forwards. All existing rows will either be NULL or will be given a default value. This makes perfect sense in the classic &ldquo;data grows vertically&rdquo; scenario. If our sales team started rewarding &ldquo;loyalty bucks&rdquo; with each purchase then the new &ldquo;loyalty bucks&rdquo; column doesn&rsquo;t make sense for all past transactions and we can set it to zero.</p><figure><img src=/assets/blog/designing-a-table-format-for-ml-workloads/vertical-table-schema-evolution.png alt="Vertical Table Schema Evolution"><figcaption>Datasets that grow vertically have no meaningful value for new columns and a default value (or NULL) is all you need to use.</figcaption></figure><p>However, this is NOT what we want when our table is growing horizontally. The entire reason we added a new column is because we&rsquo;ve calculated some new feature value for all of our rows! So, how do we add this new column in a classic table format? It&rsquo;s simple, we copy all of our data.</p><div class=image-grid><img src=/assets/blog/designing-a-table-format-for-ml-workloads/one-banana-meme.png alt="Data Copy Meme">
<em>I mean, it&rsquo;s one billion rows Michael, what could it require, 50 gigabytes?</em></div><p>Well, that&rsquo;s ok&mldr;a data copy isn&rsquo;t that expensive. Unless&mldr;</p><figure><img src=/assets/blog/designing-a-table-format-for-ml-workloads/one-billion-rows.png alt="One Billion Rows Comparison"><figcaption>Scale comparison: 1B rows TPC-H ~45 GB vs 1B rows FineWeb Prompt Data ~2,100 GB vs 1B rows small images w/ Captions ~250,100 GB</figcaption></figure><p>Well, that&rsquo;s ok&mldr;how many new columns are we really going to be adding&mldr;</p><div class=image-grid><img src=/assets/blog/designing-a-table-format-for-ml-workloads/moar-features.png alt="More Features">
<em>&ldquo;Don&rsquo;t forget the has_weird_pink_tree feature, we use that one to detect springtime.&rdquo;</em></div><p>Ok, maybe this is a problem we actually need to solve&mldr;</p><h4 id=lance-table-feature-one-two-dimensional-storage>Lance Table Feature One: Two-dimensional Storage</h4><p>So how does Lance solve this? With more complexity magic. Lance has a <em>two-dimensional storage layout</em>. Rows are divided (vertically) into fragments. Fragments are divided (horizontally) into data files. Each data file in a fragment has the same number of rows and provides one or more columns of data. This is different from traditional table formats which only have one dimension.</p><figure><img src=/assets/blog/designing-a-table-format-for-ml-workloads/2d-storage.png alt="2D Storage Layout"><figcaption>Each fragment can have any number of data files. Each data file in a fragment must have the same number of rows.</figcaption></figure><p>Initially, as we write new rows, we create one data file per fragment. When we add a new column, instead of rewriting the fragment, we add a new data file to the fragment. In fact, we can use this trick to do a lot of cool things, like splitting a fragment when we update it, but we&rsquo;ll save the advanced tricks for a future blog post. For now, let&rsquo;s focus on our horizontally growing table.</p><figure><img src=/assets/blog/designing-a-table-format-for-ml-workloads/2d-schema-evolution.png alt="2D Schema Evolution"><figcaption>Two-Dimensional Storage Evolution: Visualization of Lance&rsquo;s storage strategy, where new columns (green) are added as separate files while existing data (red) remains untouched, enabling efficient schema evolution.</figcaption></figure><p>Every time users add a new column, we write a new data file for each fragment. We don&rsquo;t need to rewrite any data (keep in mind that the &ldquo;fragments&rdquo; are not files, just lists in the manifest, so we can modify those). At some point, as we start to get hundreds or thousands of files per fragment, we may want to merge some of these together, which <em>will</em> require a rewrite (tbh, I haven&rsquo;t experienced this need yet but I&rsquo;m playing devil&rsquo;s advocate). However, that rewrite can be done strategically. The large columns (remember: 90%+ of our data) can be left alone and we only need to combine and rewrite the smaller columns.</p><h4 id=rebuttal-why-not-two-tables>Rebuttal: Why not Two Tables?</h4><p>There is another way this problem can be solved, which is perhaps more classic, but also more limiting. The two-table approach, perhaps also called the &ldquo;url-only-in-db&rdquo; approach, splits the large data and the small data into two different tables, joined with a foreign key of some kind. A specialized storage engine (like Lance) can be used for the large data, while traditional table formats can be used for the small data.</p><p>There is nothing particularly wrong here but we find that it ends up being more work than the two-dimensional storage approach described above. You need to come up with some kind of mechanism for keeping the two tables in sync through all the various table format operations. In fact, what you end up doing, is creating a new table format.</p><p>It also quickly becomes difficult to know when a column is &ldquo;for the big table&rdquo; and when a column is &ldquo;for the little table&rdquo;. For example, you might want to put your vector embeddings in the large table with your images so you can avoid rewriting those when you add new features. However, vector embeddings are actually something that are regularly replaced (when a new model comes long) or added and removed (to support different search models). You probably want to make sure you&rsquo;re not rewriting your images every time you change your embedding model. This means you either need a third table, your &ldquo;big data table&rdquo; needs to utilize two-dimensional storage, or you give up and put the embeddings back in the small table.</p><div class="admonition note inline"><div class=admonition-content><div class=admonition-title>Note</div><em>Quad-table storage format</em> sounds cool but I hope it never exists.</div></div><h3 id=search-is-everywhere>&ldquo;Search&rdquo; is Everywhere</h3><p>We got our start building vector search and so it&rsquo;s no surprise we handle that case quite well. What <em>did</em> surprise us was that search started to pop up <em>everywhere</em>. You just need to know the trick: no one ever ever calls it search. Let&rsquo;s explore some sample things people did ask for,</p><ul><li>These feature columns are based on an external dataset that changes all the time so every day I need to pull down the changes. But that&rsquo;s ok, the batch of updates has a foreign key column and so I can use that to update all those rows with new values.</li><li>My data has a tags column where we&rsquo;ve classified the data into a few different thousand tags. Each row has one or more tags. When we test our model we often test just one or two tags. It&rsquo;s just a small chunk of the data so it shouldn&rsquo;t take long to load.</li><li>We want to test our model on pictures of cats. The data isn&rsquo;t labeled in this way but there&rsquo;s a &ldquo;caption&rdquo; column. Just give us all the images that have cat or kitten or feline or whatever in the caption column.</li></ul><h4 id=lance-table-feature-two-indices--random-access>Lance Table Feature Two: Indices & Random Access</h4><p>The humble index has been synonymous with databases since&mldr;forever. However, as OLAP processing moved into columnar storage (and into the cloud) a strange thing happened. It turned out that sequential access of columnar data was so fast, and random access to column data was so slow, that indices were no longer required. Even if you could identify exactly what bits of data you wanted, there was little benefit from reducing the total amount of I/O.</p><figure><img src=/assets/blog/designing-a-table-format-for-ml-workloads/S3-Read-Amplification.png alt="S3 Read Amplification"><figcaption>There might be some extra room in the truck.</figcaption></figure><p>LanceDB (the company, not the table format) has changed this equation in a number of different ways. The Lance file format minimizes the number of IOPs and amount of data that needs read. We&rsquo;ve also embraced the fact that many of our users are either running locally or have some kind of filesystem caching layer. In fact, a page cache is a big part of our enterprise architecture. As a result, the access patterns have swapped, and the forgotten index has once become essential.</p><figure><img src=/assets/blog/designing-a-table-format-for-ml-workloads/S3-No-Amplification-Cause-Cache-4-.png alt="S3 No Amplification with Cache"><figcaption>No refunds for drones throwing results in your face</figcaption></figure><p>Fortunately, while Lance obviously has vector indices, we also have a variety of indices for non-vector data. We use these indices internally, when available, to speed up a number of table format tasks. Let&rsquo;s look at the examples above.</p><p>Indices on <strong>foreign key columns</strong> make it super fast to find matching rows and apply updates. Classically, this kind of task would be done with a hash join on the foreign key column. If we have a btree index on the foreign key column we can skip this step entirely. In fact, we can do key-deduplicating writes without any I/O into the old data. This makes things faster even if you don&rsquo;t have any kind of caching layer.</p><div class="admonition note inline"><div class=admonition-content><div class=admonition-title>Note</div>A hash join on the foreign key column is pretty much the same thing as building a btree index on the fly. In other words, the old approach was to rebuild a btree index on every single operation!</div></div><p>In the <strong>tags filtering</strong> example we run into a general expectation our users have. &ldquo;It&rsquo;s just a small chunk of the data so it shouldn&rsquo;t take long to load&rdquo;. Unfortunately, string filtering, and string loading, can be surprisingly expensive. Let&rsquo;s say we have one billion rows, a &ldquo;tags&rdquo; column might easily be 50-80GB, and performing billions of string comparison operations can be pretty time consuming. However, if there&rsquo;s an index (in this case a label_list index), then we can quickly start returning results and the entire query will likely be much faster, especially if the data is in-cache.</p><p>In the last, example, involving <strong>captions</strong>, we encounter a surprising relationship. Nearest neighbor search, in threshold mode, can turn &ldquo;search indices&rdquo; (like vector indices or full text indices) into a tool that can be used for filtering. We wanted to find all relevant images (cat or kitten or feline). This is exactly the kind of problem that full text search is good at solving. You can either discover a threshold that gives you the correct results or simply pull back a large number of results in FTS order and find the point the results are no longer relevant.</p><figure><img src=/assets/blog/designing-a-table-format-for-ml-workloads/FTS-Thresholds-1-.png alt="FTS Thresholds"><figcaption>Search Threshold Analysis: Comparison of semantic search versus full-text search approaches, demonstrating how different search strategies handle variations in query terms and context.</figcaption></figure><p>Existing table formats will often tackle these problems with clustering (a.k.a <em>primary indices</em>). They&rsquo;ve even come up with some pretty cool innovations here like liquid clustering and z-order clustering which make it easier to handle multiple columns. However, these approaches are often limited in the number of scenarios they can address, there are only so many columns that you can use as primary indices. They also would rely on rewrites for new columns. Even if you were to add two-dimensional storage, you would need a rewrite if you wanted your new column to participate in a primary index.</p><p>I think there is a lot of good in primary indices. They have better I/O patterns (don&rsquo;t require random access) since the data is ordered and they are much smaller than secondary indices. We need to get better primary index support into Lance at some point. Still, the data rewriting problem is significant, and it has prevented us from being to take advantage of primary indices in many situations.</p><h3 id=the-well-rounded-implementation>The Well Rounded Implementation</h3><p>The final issue we encountered is that most table libraries we tried had focused most their time and effort on the query problem. This makes a lot of sense. OLAP is big and complicated. Distributed query engines are cool and fun. Unfortunately, we end up with a bit of an unbalanced implementation.</p><figure><img src=/assets/blog/designing-a-table-format-for-ml-workloads/Unbalanced-Query-Engine-1-.png alt="Unbalanced Query Engine"><figcaption>Yes, those are consummate V&rsquo;s (IYKYK).</figcaption></figure><p>At LanceDB, we&rsquo;ve discovered that working with big data means that <em>everything is hard</em>. Importing initial data needs to be done in parallel and distributed because even small numbers of rows can mean tons of data. Adding a new column might need to be a task that runs in parallel because we&rsquo;re using a complex model to calculate our features and it can be expensive to calculate even a single row&rsquo;s value. Calculating an index needs to be something we can partition across multiple workers. The list goes on.</p><p>Basically, the way I like to think of it, is that we need the same API as a regular database (insert, create index, alter column, etc.) but every single thing needs to be capable of running in parallel, and ready to handle big data (don&rsquo;t get us started on batch sizes and RAM consumption ðŸ˜…).</p><p>To be fair, I don&rsquo;t think we&rsquo;ve got the perfect user friendly API for many of these things. Also, these are primarily library concerns, as most formats can support these operations in parallel. However, these are challenges we are taking on head first, and we&rsquo;ve heard multiple times from users that we seem to be getting it right so far.</p><h2 id=whats-next>What&rsquo;s Next</h2><p>First, we still have work to do to make sure that we&rsquo;re doing all the things I&rsquo;ve described above in the best way possible. We wanted to start writing about this to share the challenges and solutions we&rsquo;ve encountered as we hope it will help the design and expansion of existing table formats.</p><p>We also want to increase our integration support. Pushing customers to use a single table format is perhaps idealistic. We recently noticed some interest in potentially <a href=https://lists.apache.org/thread/ovyh52m2b6c1hrg4fhw3rx92bzr793n2>adding the Lance file format to Iceberg</a> and this kind of integration is very exciting. We&rsquo;re also excited by the many unified front-ends to table formats that have arisen. The not-exactly-official &ldquo;<a href=https://arrow.apache.org/docs/python/generated/pyarrow.dataset.Dataset.html>pyarrow datasets protocol</a>&rdquo; has allowed us to integrate with tools like DuckDB and Polars. <a href=https://datafusion.apache.org/>Datafusion</a> gives us the &ldquo;table provider&rdquo; trait and we&rsquo;re seeing more and more things that can consume that. <a href=https://arrow.apache.org/docs/format/FlightSql.html>Flight SQL</a> gives as a unified &ldquo;SQL frontend&rdquo;. Tools like <a href=https://xtable.apache.org/>XTable</a> could even provide metadata-level compatibility.</p><p>Work on catalogs is starting to ramp up and provide unified APIs for database management and we&rsquo;re following these moves closely. We&rsquo;d also like to continue our work developing new kinds of indices. All of our indices are just plain Arrow data (in Lance files) and could be useful elsewhere too. Through the arrow-verse, and the idea of composable data systems, we are finding that users are able to use the right tool for the right job without hard-locking into dependencies.</p><p>If you&rsquo;re interested in adding an integration to Lance or learning more about our table format, hop on over to our <a href=https://discord.gg/G5DcmnZWKB>Discord</a> or <a href=https://github.com/lancedb/lance>Github</a> and we&rsquo;d be happy to talk to you!</p><h2 id=special-thanks>Special Thanks</h2><p>Special thanks to the pets from LanceDB who would like to mention that these photos were perhaps not taken from the most flattering angles.</p><div class=image-grid><img src=/assets/blog/designing-a-table-format-for-ml-workloads/Pets-Biliography.png alt="Pet Bibliography">
<em>Meet the Team: Uni (orange and white) and Lance (white) - our feline quality assurance specialists. And yes, Lance&rsquo;s name truly is a delightful coincidence!</em></div></div></article><div class=author-section><img src=/assets/authors/weston-pace.jpg alt="Weston Pace" class=author-avatar><div class=author-info><h3 class=author-name>Weston Pace</h3><p class=author-bio>Data engineer from the open source space, working on LanceDB, Arrow, Substrait.</p><div class=author-social><a href=https://twitter.com/westonpace target=_blank rel=noopener><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M23 3a10.9 10.9.0 01-3.14 1.53 4.48 4.48.0 00-7.86 3v1A10.66 10.66.0 013 4s-4 9 5 13a11.64 11.64.0 01-7 2c9 5 20 0 20-11.5a4.5 4.5.0 00-.08-.83A7.72 7.72.0 0023 3z"/></svg>
Twitter
</a><a href=https://github.com/westonpace target=_blank rel=noopener><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg>
GitHub
</a><a href=https://linkedin.com/in/westonpace target=_blank rel=noopener><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M16 8a6 6 0 016 6v7h-4v-7a2 2 0 00-2-2 2 2 0 00-2 2v7h-4v-7a6 6 0 016-6z"/><rect x="2" y="9" width="4" height="12"/><circle cx="4" cy="4" r="2"/></svg>
LinkedIn</a></div></div></div><div class=related-posts><h2>Related Posts</h2><div class=related-posts-grid><article class=related-post><a href=/blog/columnar-file-readers-in-depth-repetition-definition-levels/><img src=/assets/blog/columnar-file-readers-in-depth-repetition-definition-levels/columnar-file-readers-in-depth-repetition-definition-levels.png alt="Columnar File Readers in Depth: Repetition & Definition Levels" class=related-preview-image></a><h3><a href=/blog/columnar-file-readers-in-depth-repetition-definition-levels/>Columnar File Readers in Depth: Repetition & Definition Levels</a></h3><div class=post-meta><span class=post-author>Weston Pace</span>
<span class=post-date>June 2, 2025</span></div></article><article class=related-post><a href=/blog/columnar-file-readers-in-depth-column-shredding/><img src=/assets/blog/columnar-file-readers-in-depth-column-shredding/columnar-file-readers-in-depth-column-shredding.png alt="Columnar File Readers in Depth: Column Shredding" class=related-preview-image></a><h3><a href=/blog/columnar-file-readers-in-depth-column-shredding/>Columnar File Readers in Depth: Column Shredding</a></h3><div class=post-meta><span class=post-author>Weston Pace</span>
<span class=post-date>May 15, 2025</span></div></article><article class=related-post><a href=/blog/columnar-file-readers-in-depth-compression-transparency/><img src=/assets/blog/columnar-file-readers-in-depth-compression-transparency/columnar-file-readers-in-depth-compression-transparency.png alt="Columnar File Readers in Depth: Compression Transparency" class=related-preview-image></a><h3><a href=/blog/columnar-file-readers-in-depth-compression-transparency/>Columnar File Readers in Depth: Compression Transparency</a></h3><div class=post-meta><span class=post-author>Weston Pace</span>
<span class=post-date>April 29, 2025</span></div></article></div></div></main></div><footer class=site-footer><div class=footer-content><a href=/ class=site-title><img src=/assets/blog/logo.png alt="LanceDB Blog" class=site-logo></a><div class=footer-links><a href=https://lancedb.com/documentation class=footer-link>Documentation</a>
<a href=https://lancedb.com/pricing class=footer-link>Pricing</a>
<a href=/get-started class="footer-link get-started">Get Started</a></div></div></footer></body></html>