<!doctype html><html lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Agentic RAG using LangGraph: Build autonomous Customer support agent - LanceDB Blog</title><link rel=stylesheet href=/css/custom.css><link rel=stylesheet href=/css/syntax-highlighting.css><script src=/js/toc-progress.js></script><script src=/js/heading-links.js></script><script src=/js/announcement.js></script><script src=/js/code-blocks.js></script></head><body><div class=announcement-bar id=announcement-bar><div class=announcement-content><span>June 1st, 2025: LanceDB Cloud is now in public beta!</span>
<a href=https://lancedb.com/cloud class=announcement-link>Try it now â†’</a>
<button class=announcement-close onclick=closeAnnouncement()>Ã—</button></div></div><header class=site-header><div class=header-content><a href=/ class=site-title><img src=/assets/blog/logo.png alt="LanceDB Blog" class=site-logo></a><div class=header-links><a href=/docs class=header-link>Documentation</a>
<a href=/pricing class=header-link>Pricing</a>
<a href=/get-started class="header-link get-started">Get Started</a></div></div></header><div class=content-wrapper><div class=toc-container><div class=toc><h2>Table of Contents</h2><nav id=TableOfContents><ul><li><ul><li><a href=#agent-whats-that>Agent? What&rsquo;s that?</a></li><li><a href=#lets-build-a-use-case-email-agent>Lets build a use case: Email Agent</a></li><li><a href=#final-notes>Final Notes</a></li></ul></li></ul></nav></div></div><main><h1>Agentic RAG using LangGraph: Build autonomous Customer support agent</h1><div class=post-meta><span class=post-author>Mahesh Deshwal</span>
<span class=meta-divider>â€¢</span>
<span class=post-date>January 26, 2025</span></div><article class=single-post><img src=/assets/blog/agentic-rag-using-langgraph-building-a-simple-customer-support-autonomous-agent/agentic-rag-using-langgraph-building-a-simple-customer-support-autonomous-agent.png alt="Agentic RAG using LangGraph: Build autonomous Customer support agent" class=preview-image><div class=post-content><h3 id=agent-whats-that>Agent? What&rsquo;s that?</h3><p>In the current world where everything is running with and for AI, retrieval-augmented generation (RAG) systems have become essential for handling simple queries and generating contextually relevant responses. However, as ever evolving human we are, the need for complex, autonomous problem-solving has emerged. Here I present, behold the mighty: <strong>AI Agents</strong> â€” autonomous entities that redefine how we interact with technology. In simple terms, it&rsquo;s a sophisticated Graph and even simpler, complex and advanced <code>for</code> loops which use LLMs as the core of working.</p><h4 id=what-good-are-these-then>What good are these then?</h4><ul><li><strong>Autonomous Problem-Solving</strong>: AI Agents operate independently, driven by goals rather than specific inputs, and adapt dynamically to new information and environments.</li><li><strong>Multi-Step Task Execution</strong>: They perform complex, multi-step tasks, maintain state across interactions, and utilize tools like machine learning and rule-based systems to achieve optimal outcomes.</li><li><strong>Versatile Capabilities</strong>: From browsing the internet and managing apps to conducting financial transactions and controlling devices, AI Agents are reshaping intelligent automation.</li></ul><h4 id=whats-langgraph>What&rsquo;s LangGraph?</h4><p>There are many tools available in the market to build agents and among the famous ones are <a href=https://www.langchain.com/langgraph>LangGraph</a>, <a href=https://github.com/microsoft/autogen>AutoGen</a>, <a href=https://github.com/openai/swarm>Swarm</a>, <a href=https://github.com/crewAIInc/crewAI>CrewAI</a> etc etc. You can choose any but we chose this one for granular control and Open Source. It basically create a Graph for your workflow and inside your Graph are:</p><ol><li><code>State</code> : <code>Pydantic Models</code> or <code>Typed Dict</code> to hold your variables and used for message passing</li><li><code>Node</code> : It is just a function that does some work. It accepts a <code>State</code> object and modifies that State</li><li><code>Tools</code> : There are pure Python functions or <code>Pydantic</code> models which your agents can call. You use the tools to do some Retrieval, Web Search, Calculator, Cal some APIs etc etc. You just have to write the definition of what it does and model will understand which tool <strong>CAN</strong> be used at any point of time.</li><li><code>Edge</code> : You have pre-defined flows which tell you the execution order of functions (Nodes) in our case</li><li><code>Conditional Edges</code> or <code>Routers</code>: Instead of fixing in previous point, we make it conditional. So If you are at <code>Node-N</code>, you decide based on a condition where you want to go to out of Nodes <code>N_i....N_x</code></li></ol><p><strong>Where does the RAG Come in?</strong></p><p>You remember our <code>tools</code> and <code>Nodes</code> above? So we can use RAG either as a tool OR a Node. You&rsquo;ll see most of the tutorials using RAG as a tool however I want to show how can you use it as a <code>Node</code> and that too conditional.</p><h3 id=lets-build-a-use-case-email-agent>Lets build a use case: Email Agent</h3><p>What is does is:</p><ol><li>Fetch the unread emails from your inbox</li><li>Look at the type of email</li><li>If it is a Policy related email, it&rsquo;ll use RAG to refer to policies to Draft the Email otherwise just create a normal draft. If it&rsquo;s a SPAM or something else, just discard it..</li><li>Proofread the Draft. If it&rsquo;s good to send, send it else send it to redraft again. Ideally, you&rsquo;d let the proof reader node know what are the criteria and then you&rsquo;d send the reasoning why it was rejected so that Drafting model improves it. That would be out of scope of this blog (wait for next one ðŸ˜„)</li><li>Once you get Okay from proof reader, send a reply. Ideally, you want an <code>interrupt</code> so that the human in the loop can review and THEN you send it but again, it&rsquo;s too much to cover here.</li><li>For sending, we just <code>print</code> for now</li></ol><p>***And Yes, All of it is Autonomous ***
[</p><p>Google Colab</p><p><img src=__GHOST_URL__/content/images/icon/favicon-22.ico alt></p><p><img src=__GHOST_URL__/content/images/thumbnail/colab_favicon_256px-22.png alt>
](<a href=https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/customer_support_agent_langgraph/LangGraph_LanceDB.ipynb>https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/customer_support_agent_langgraph/LangGraph_LanceDB.ipynb</a>)
Let&rsquo;s get some policies and build our RAG on top of that</p><pre><code>pip install -U colorama langgraph langchain-community langchain-openai langchain-anthropic tavily-python pandas openai lancedb sentence-transformers



from langchain_core.messages import ToolMessage, SystemMessage, AIMessage, HumanMessage
from langchain_core.runnables import RunnableLambda
from langgraph.prebuilt import ToolNode
from langchain_core.runnables import Runnable, RunnableConfig
from typing import TypedDict, Annotated
from langgraph.graph.message import AnyMessage, add_messages
from langchain_openai import ChatOpenAI
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import END, StateGraph, START
from langgraph.prebuilt import tools_condition
import torch

# ------------ Vector Search ----------------

import lancedb, re, requests
from lancedb.pydantic import LanceModel, Vector
from lancedb.embeddings import get_registry
import numpy as np
from langchain_core.tools import tool

# ------- Vecot DB using Lance DB ------------
model = get_registry().get(&quot;sentence-transformers&quot;).create(name=&quot;BAAI/bge-small-en-v1.5&quot;, device=&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)

class Policy(LanceModel):
    text: str = model.SourceField()
    vector: Vector(model.ndims()) = model.VectorField()


response = requests.get(
    &quot;https://storage.googleapis.com/benchmarks-artifacts/travel-db/swiss_faq.md&quot;
)
response.raise_for_status()
faq_text = response.text


class VectorStoreRetriever:
    def __init__(self, db_path:str, table_name:str, model, docs: list, schema, ):
        self.db = lancedb.connect(db_path)
        self.table = self.db.create_table(table_name, schema = schema)
        self.table.add([{&quot;text&quot;: txt} for txt in re.split(r&quot;(?=\n##)&quot;, faq_text)])

    def query(self, query: str, k: int = 5) -&gt; list[dict]:
        result = self.table.search(query).limit(k).to_list()
        return [{&quot;page_content&quot;: item[&quot;text&quot;], &quot;similarity&quot;: 1- item[&quot;_distance&quot;]} for item in result]


retriever = VectorStoreRetriever(&quot;./lancedb&quot;, &quot;company_policy&quot;, model, faq_text, Policy)
</code></pre><p>Now that we have our documents, ready, let&rsquo;s build some helpers including a Dummy Function to fetch your email. In real world, you replace it with your logic and APIs</p><pre><code>from typing import Optional, List
from pydantic import BaseModel
from langchain_core.prompts import PromptTemplate
from langchain_openai import AzureChatOpenAI
from langgraph.graph import END, StateGraph, START
import os
from dotenv import load_dotenv
import random
from typing import Annotated
from langgraph.graph.message import AnyMessage, add_messages
from typing_extensions import TypedDict
from langchain_core.messages import ToolMessage, SystemMessage, AIMessage, HumanMessage
from langchain_core.runnables import RunnableLambda
from langgraph.prebuilt import ToolNode
from langchain_core.runnables import Runnable, RunnableConfig
from langgraph.checkpoint.memory import MemorySaver
from langgraph.prebuilt import tools_condition
import lancedb, re, requests
from lancedb.pydantic import LanceModel, Vector
from lancedb.embeddings import get_registry
import numpy as np
from langchain_core.tools import tool
from google.colab import userdata # use os.environ.get()
import os
from colorama import Fore, Style

memory = MemorySaver() # it'll save the all the states and history corresponding to a `thread_id`. We can get previous conversations if we use memory

# llm = ChatOpenAI(model=&quot;gpt-3.5-turbo&quot;) # use any
def setup_llm():
    return AzureChatOpenAI(
        api_key=userdata.get(&quot;AZURE_OPENAI_API_KEY&quot;),
        api_version=userdata.get(&quot;AZURE_OPENAI_API_MODEL_VERSION&quot;),
        azure_endpoint=userdata.get(&quot;AZURE_OPENAI_API_ENDPOINT&quot;),
        azure_deployment=userdata.get(&quot;AZURE_OPENAI_API_DEPLOYMENT_NAME&quot;),
        temperature=0.7
    )


def create_dummy_random_emails():
    items = [
        {
            &quot;subject&quot;: &quot;Invoice Request for Recent Flight Booking&quot;,
            &quot;body&quot;: &quot;Dear SWISS Team, I recently booked a flight with SWISS (Booking Reference: LX123456) and would like to request an invoice for my records. Could you please guide me on how to obtain it? Thank you, Anna MÃ¼ller&quot;
        },
        {
            &quot;subject&quot;: &quot;Rebooking Inquiry for Upcoming Flight&quot;,
            &quot;body&quot;: &quot;Hello, I need to change the travel dates for my flight (Booking Reference: LX789012). Can you confirm if this is possible and what fees might apply? Best regards, John Smith&quot;
        },
        {
            &quot;subject&quot;: &quot;Cancellation of Flight LX345678&quot;,
            &quot;body&quot;: &quot;Hi SWISS Customer Service, I need to cancel my flight (Booking Reference: LX345678) due to unforeseen circumstances. Could you please explain the cancellation process and any associated fees? Sincerely, Maria Gonzalez&quot;
        },
        {
            &quot;subject&quot;: &quot;Request for Special Invoice for Italy&quot;,
            &quot;body&quot;: &quot;Dear SWISS, I booked a flight originating in Italy and require a special invoice for tax purposes. Can you assist me with this request? Kind regards, Luca Rossi&quot;
        },
        {
            &quot;subject&quot;: &quot;Payment Issue with Credit Card&quot;,
            &quot;body&quot;: &quot;Hello, I tried to pay for my booking using my Visa card, but the payment failed. Can you confirm if the issue is with my card or the payment system? Thanks, Emily Brown&quot;
        },
        {
            &quot;subject&quot;: &quot;Refund Status for Cancelled Flight&quot;,
            &quot;body&quot;: &quot;Dear SWISS, I cancelled my flight (Booking Reference: LX456789) two weeks ago and was told I would receive a refund. Could you provide an update on the status? Best, David Johnson&quot;
        },
        {
            &quot;subject&quot;: &quot;Seat Reservation Inquiry&quot;,
            &quot;body&quot;: &quot;Hi, I have a booking (Reference: LX567890) and would like to confirm if my seat reservation will be retained after a rebooking. Please advise. Regards, Sophie Lee&quot;
        },
        {
            &quot;subject&quot;: &quot;Upgrade Request for Economy Flex Fare&quot;,
            &quot;body&quot;: &quot;Dear SWISS, I booked an Economy Flex fare and would like to upgrade to Business Class. Can you guide me on how to proceed? Thank you, Michael Chen&quot;
        },
        {
            &quot;subject&quot;: &quot;Group Booking Inquiry&quot;,
            &quot;body&quot;: &quot;Hello, I am planning to book flights for a group of 12 passengers. Can you provide details on group booking options and any discounts? Best, Sarah Wilson&quot;
        },
        {
            &quot;subject&quot;: &quot;Issue with Online Booking Platform&quot;,
            &quot;body&quot;: &quot;Hi SWISS, I am unable to see my recent booking in my profile on the SWISS website. Can you help resolve this issue? Regards, Thomas Anderson&quot;
        }
    ]
    chosen_items = [random.choice(items) for _ in range(random.randint(0,2))]
    return [Email(id=str(i), sender=&quot;some_user@example.mail&quot;, subject=item[&quot;subject&quot;], body=item[&quot;body&quot;]) for i, item in enumerate(chosen_items)]
</code></pre><p><strong>Let&rsquo;s setup our Email Agent:</strong></p><p>First one is our <code>Email</code> object which basically tells us what an Email is. The second one is the <code>State</code> which will be used inside the graph</p><pre><code>class Email(BaseModel):
    id: str
    sender: str
    subject: str
    body: str
    final_reply: str = &quot;&quot;
    status: str = &quot;pending&quot;  # pending, sent, failed, skipped
    failure_reason: str = &quot;&quot;

class EmailState(BaseModel):
    emails: List[Email] = [] # List of the Unread above Email class 
    processed_emails: List[Email] = [] # Final emails with the replies and denial reason
    current_email: Optional[Email] = None # Pop one everytime from the above list
    policy_context: Optional[str] = &quot;&quot; # Rag context for CURRENT email
    draft: str = &quot;&quot; # Current Draft of the Current Email
    trials: int = 0 # Trails done for Draft &lt;-&gt; Proof Read for current email
    allowed_trials: int = 3 # do Drft &lt;-&gt; Proof Read a max of 3 times
    sendable: bool = False # send the current email if True
    exit:bool = False # There are no unread emails left
</code></pre><p>Let&rsquo;s setup our Agent Classes and simple functions. Names and Prompts are self explanatory. Out **LanceDB **RAG is used in the function <code>lookup_policy</code> to fetch policies if the query requires searching the internal policies.</p><pre><code>class EmailAgent:
    def __init__(self):
        self.llm = setup_llm() # Replace with your LLM you want

    def fetch_unread_emails(self) -&gt; List[Email]:
      &quot;&quot;&quot;
      Replace this with your Email LOGIC
      &quot;&quot;&quot;
      return create_dummy_random_emails()

    def lookup_policy(self, subject: str, body:str) -&gt; str:
        &quot;&quot;&quot;Always Consult the company policies to answer the queries.
        Use this for drafting the emails&quot;&quot;&quot;
        prompt = PromptTemplate(template=&quot;Identify whether the given email is policy related or not. Identify if the email requires info which might be in the policy documents.\n\nSubject: {subject}\n\nBody:\n{body}\n\n. Do not output any reasoning etc. Strictly reply with Yes/No&quot;, input_variables=[&quot;email&quot;])
        chain = prompt | self.llm
        response = chain.invoke({&quot;subject&quot;: subject, &quot;body&quot;: body})
        policy_related = response.content.strip().lower() == &quot;yes&quot;
        if policy_related:
          docs = retriever.query(f&quot;Email Subject: {subject}\n\nEmail Body:\n{body}&quot;, k=2)
          return &quot;\nPolicy Context:&quot; + &quot;\n\n&quot;.join([doc[&quot;page_content&quot;] for doc in docs])
        return &quot;&quot;

    def draft_email(self, email_subject:str, email_body: str, email_context:str = &quot;&quot;) -&gt; str:
        if not email_context:
          prompt = PromptTemplate(template=&quot;You are a specialised chat agent named Saleem Shady' working for SWISS Airline. Write a well professional response to this user email:\n\nEmail Subject: {email_subject}\n\nEmail Body:\n{email_body}\n\nResponse:&quot;, input_variables=[&quot;email&quot;])
        else:
          prompt = PromptTemplate(template=&quot;You are a specialised chat agent named Saleem Shady' working for SWISS Airline. Write a well professional response to this user email given the Context (which may or may not be required in answering)\n\n{email_context}\n\nEmail Subject: {email_subject}\n\nEmail Body:\n{email_body}\n\nResponse:&quot;, input_variables=[&quot;email&quot;])

        chain = prompt | self.llm
        response = chain.invoke({&quot;email_subject&quot;:email_subject,&quot;email_body&quot;: email_body, &quot;email_context&quot;: email_context})
        return response.content


    def validate_draft(self, initial_email: str, draft_email: str) -&gt; bool:
        prompt = PromptTemplate(template=&quot;You are a Email Proofreader. Review this response:\n\nOriginal Email:\n{initial_email}\n\nDraft Response:\n{draft_email}\n\nIs this mail ready to send? Do not give your reasoning or views. Reply only with (Yes/No):&quot;, input_variables=[&quot;initial_email&quot;, &quot;draft_email&quot;])
        chain = prompt | self.llm
        response = chain.invoke({&quot;initial_email&quot;: initial_email, &quot;draft_email&quot;: draft_email})
        return response.content.strip().lower() == &quot;yes&quot;
</code></pre><p>Now let&rsquo;s setup our main <code>Workflow</code> which is why you came here. The below functions are Either <code>Nodes</code> or <code>Routers</code> . Which we&rsquo;ll get to know when we build the nodes and define edges</p><pre><code>    agent = EmailAgent()

    def fetch_emails(state: EmailState) -&gt; EmailState:
        emails = agent.fetch_unread_emails()
        state.emails = emails
        return state

    def process_next_email(state: EmailState) -&gt; EmailState:
      if state.emails:
          state.current_email = state.emails.pop(0)
          state.policy_context = agent.lookup_policy(state.current_email.subject, state.current_email.body)
      else:
          state.exit = True
      return state

    def draft_email(state: EmailState) -&gt; EmailState:
        if state.current_email:
            state.draft = agent.draft_email(state.current_email.subject, state.current_email.body, state.policy_context)
            state.trials += 1
        return state

    def validate_draft(state: EmailState) -&gt; EmailState:
        if state.current_email and state.draft:
            state.sendable = agent.validate_draft(state.current_email.body, state.draft)
        return state

    def decide_next_step(state: EmailState) -&gt; str:
        if state.sendable:
            print(&quot;\n\n-----------------------Sending Email ---------------\n\n&quot;)
            return &quot;send&quot;
        elif state.trials &gt;= state.allowed_trials:
            state.current_email.status = &quot;failed&quot;
            state.current_email.failure_reason = &quot;Failed after 3 attempts&quot;
            print(&quot;\n\n*********************** Draft Failed after Max Tries ******************** \n\n&quot;)
            return &quot;stop&quot;
        else:
            return &quot;rewrite&quot;

    def send_or_skip_email(state: EmailState) -&gt; EmailState:
        if state.current_email.status != &quot;failed&quot;:
            print(f&quot;\n\nSending email: {state.draft}&quot;)
            state.current_email.final_reply = state.draft
            state.current_email.status = &quot;sent&quot;
            state.processed_emails.append(state.current_email)

        # Reset state for the next email
        state.current_email = None
        state.draft = &quot;&quot;
        state.trials = 0
        state.policy_context = &quot;&quot;
        return state
</code></pre><p>Let&rsquo;s Define the <code>Nodes</code> and <code>Edges / Conditional Edges</code></p><pre><code>    workflow.add_node(&quot;fetch_emails&quot;, fetch_emails)
    workflow.add_node(&quot;process_next_email&quot;, process_next_email)
    workflow.add_node(&quot;draft_email&quot;, draft_email)
    workflow.add_node(&quot;validate_draft&quot;, validate_draft)
    workflow.add_node(&quot;send_or_skip_email&quot;, send_or_skip_email)

    workflow.add_edge(START, &quot;fetch_emails&quot;)
    workflow.add_edge(&quot;fetch_emails&quot;, &quot;process_next_email&quot;)

    workflow.add_conditional_edges(
        &quot;process_next_email&quot;,
        lambda state: END if state.exit else &quot;draft_email&quot; ,
        {&quot;draft_email&quot;: &quot;draft_email&quot;, END: END}
        )

    workflow.add_edge(&quot;draft_email&quot;, &quot;validate_draft&quot;)

    workflow.add_conditional_edges(
        &quot;validate_draft&quot;,
        decide_next_step,
        {&quot;send&quot;: &quot;send_or_skip_email&quot;, &quot;rewrite&quot;: &quot;draft_email&quot;, &quot;stop&quot;: &quot;send_or_skip_email&quot;}
    )

    workflow.add_edge(&quot;send_or_skip_email&quot;, &quot;process_next_email&quot;)

    compiled_email_subgraph = workflow.compile()
</code></pre><p>Want to see how our graph looks?</p><pre><code>initial_state = EmailState()

from IPython.display import Image, display
try:
    display(Image(compiled_email_subgraph.get_graph(xray=True).draw_mermaid_png()))
except Exception:
    pass
</code></pre><p><img src=__GHOST_URL__/content/images/2025/01/download.png alt>
You can match the graph working with what we discussed the in the workflow. Let&rsquo;s put it to work. (Uncomment if you want to see the <code>State</code> at each point)</p><pre><code>print(Fore.GREEN + &quot;Starting workflow...&quot; + Style.RESET_ALL)
for output in compiled_email_subgraph.stream(initial_state):
    for key, value in output.items():
        print(Fore.CYAN + f&quot;Finished running: {key}&quot; + Style.RESET_ALL)
        # print(Fore.YELLOW + f&quot;State after {key}:&quot; + Style.RESET_ALL)
        # print(value)
</code></pre><p><img src=__GHOST_URL__/content/images/2025/01/Screenshot-from-2025-01-19-13-42-50.png alt>
You see, one failed after 3 times and one got sent successfulAgentic RAG using LangGraph: Build autonomous Customer support agently. Which means that you need to tweak your prompts, add the validator reasoning and guidance etc according to the data and use case
[</p><p>Google Colab</p><p><img src=__GHOST_URL__/content/images/icon/favicon-23.ico alt></p><p><img src=__GHOST_URL__/content/images/thumbnail/colab_favicon_256px-23.png alt>
](<a href=https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/customer_support_agent_langgraph/LangGraph_LanceDB.ipynb>https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/customer_support_agent_langgraph/LangGraph_LanceDB.ipynb</a>)</p><h3 id=final-notes>Final Notes</h3><p>So now that we&rsquo;ve built a working agent that takes care of things for you, one thing to notice is that it relies heavily on fetching the right context which is where LanceDB stands out as a powerful tool because of it&rsquo;s ability to efficiently handle (in memory) vector search thus making it an invaluable whether you&rsquo;re doing a quick POC or putting your stuff to production.</p><p>Keep yourself posted to learn some advanced Agentic concepts (like Human in the Loop, Memory, Multi Agents etc etc) further enhanced by LanceDB&rsquo;s powerful filtering to push RAG accuracy even further.</p></div></article><div class=author-section><img src=/assets/authors/default-avatar.png alt="Mahesh Deshwal" class=author-avatar><div class=author-info><h3 class=author-name>Mahesh Deshwal</h3><div class=author-social></div></div></div><div class=related-posts><h2>Related Posts</h2><div class=related-posts-grid><article class=related-post><a href=/blog/columnar-file-readers-in-depth-repetition-definition-levels/><img src=/assets/blog/columnar-file-readers-in-depth-repetition-definition-levels/columnar-file-readers-in-depth-repetition-definition-levels.png alt="Columnar File Readers in Depth: Repetition & Definition Levels" class=related-preview-image></a><h3><a href=/blog/columnar-file-readers-in-depth-repetition-definition-levels/>Columnar File Readers in Depth: Repetition & Definition Levels</a></h3><div class=post-meta><span class=post-author>Weston Pace</span>
<span class=post-date>June 2, 2025</span></div></article><article class=related-post><a href=/blog/columnar-file-readers-in-depth-column-shredding/><img src=/assets/blog/columnar-file-readers-in-depth-column-shredding/columnar-file-readers-in-depth-column-shredding.png alt="Columnar File Readers in Depth: Column Shredding" class=related-preview-image></a><h3><a href=/blog/columnar-file-readers-in-depth-column-shredding/>Columnar File Readers in Depth: Column Shredding</a></h3><div class=post-meta><span class=post-author>Weston Pace</span>
<span class=post-date>May 15, 2025</span></div></article><article class=related-post><a href=/blog/columnar-file-readers-in-depth-compression-transparency/><img src=/assets/blog/columnar-file-readers-in-depth-compression-transparency/columnar-file-readers-in-depth-compression-transparency.png alt="Columnar File Readers in Depth: Compression Transparency" class=related-preview-image></a><h3><a href=/blog/columnar-file-readers-in-depth-compression-transparency/>Columnar File Readers in Depth: Compression Transparency</a></h3><div class=post-meta><span class=post-author>Weston Pace</span>
<span class=post-date>April 29, 2025</span></div></article></div></div></main></div><footer class=site-footer><div class=footer-content><a href=/ class=site-title><img src=/assets/blog/logo.png alt="LanceDB Blog" class=site-logo></a><div class=footer-links><a href=https://lancedb.com/documentation class=footer-link>Documentation</a>
<a href=https://lancedb.com/pricing class=footer-link>Pricing</a>
<a href=/get-started class="footer-link get-started">Get Started</a></div></div></footer></body></html>