---
title: "Embedding Providers"
sidebar_title: Embeddings
description: "Supported embedding providers for LanceDB"
hide_toc: true
weight: 20
---

| Provider | Description |
|:---------|:------------|
| [OpenAI](/docs/integrations/embedding/openai) | Text embedding models (text-embedding-ada-002, text-embedding-3-small, text-embedding-3-large) |
| [Sentence Transformers](/docs/integrations/embedding/sentence-transformers) | BERT-based sentence embedding models with mean pooling |
| [VoyageAI](/docs/integrations/embedding/voyageai) | Transformer-based text embedding models (voyage-large-2, voyage-code-2) |
| [IBM](/docs/integrations/embedding/ibm) | BERT-based text embedding models via Watson AI services |
| [Instructor](/docs/integrations/embedding/instructor) | Instruction-tuned BERT models for task-specific embeddings |
| [Jina](/docs/integrations/embedding/jina) | Multilingual BERT models optimized for semantic similarity |
| [Ollama](/docs/integrations/embedding/ollama) | Local inference of embedding models (nomic-embed-text, all-minilm) |
| [AWS](/docs/integrations/embedding/aws) | Titan text embedding models via Amazon Bedrock API |
| [Cohere](/docs/integrations/embedding/cohere) | Multilingual text embedding models (embed-english-v3.0, embed-multilingual-v3.0) |
| [Gemini](/docs/integrations/embedding/gemini) | Multimodal embedding models for text and image inputs |
| [Hugging Face](/docs/integrations/embedding/huggingface) | Access to transformer-based embedding models from Hugging Face Hub |
| [OpenCLIP](/docs/integrations/embedding/openclip) | CLIP-based multimodal models for text-image embeddings |
| [ImageBind](/docs/integrations/embedding/imagebind) | Unified embedding model for text, image, audio, video, depth, and thermal data |
