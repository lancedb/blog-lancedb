---
title: "RAG Tutorials"
sidebar_title: "RAG"
description: "Explore a variety of RAG (Retrieval-Augmented Generation) applications with LanceDB."
---

This section provides a curated list of advanced RAG techniques and examples to help you build powerful and intelligent applications with LanceDB.

| RAG Technique | Description | Links |
| --- | --- | --- |
| Contextual RAG | Improves retrieval by combatting the "lost in the middle" problem. This technique uses an LLM to generate succinct context for each document chunk, then prepends that context to the chunk before embedding, leading to more accurate retrieval. | [Open in Colab](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/Contextual-RAG/Anthropic_Contextual_RAG.ipynb)<br>[View on GitHub](https://github.com/lancedb/vectordb-recipes/tree/main/examples/Contextual-RAG) |
| Matryoshka Embeddings | Demonstrates a RAG pipeline using Matryoshka Embeddings with LanceDB and Llamaindex. This method allows for efficient storage and retrieval of nested, variable-sized embeddings. | [Open in Colab](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/tutorials/RAG-with_MatryoshkaEmbed-Llamaindex/RAG_with_MatryoshkaEmbedding_and_Llamaindex.ipynb)<br>[View on GitHub](https://github.com/lancedb/vectordb-recipes/tree/main/tutorials/RAG-with_MatryoshkaEmbed-Llamaindex) |
| HyDE (Hypothetical Document Embeddings) | An advanced RAG technique that uses an LLM to generate a "hypothetical" document in response to a query. This hypothetical document is then used to retrieve actual, similar documents, improving relevance. | [Open in Colab](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/Advance-RAG-with-HyDE/main.ipynb)<br>[View on GitHub](https://github.com/lancedb/vectordb-recipes/tree/main/examples/Advance-RAG-with-HyDE) |
| Late Chunking | An advanced RAG method where documents are retrieved first, and then chunking is performed on the retrieved documents just before synthesis. This helps maintain context that might be lost with pre-chunking. | [Open in Colab](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/Advanced_RAG_Late_Chunking/Late_Chunking_(Chunked_Pooling).ipynb)<br>[View on GitHub](https://github.com/lancedb/vectordb-recipes/tree/main/examples/Advanced_RAG_Late_Chunking) |
| Parent Document Retriever | A RAG strategy that involves splitting documents into smaller child chunks for searching, but retrieving the larger parent chunk for context. This provides the LLM with more complete information to generate a better response. | [Open in Colab](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/parent_document_retriever/main.ipynb)<br>[View on GitHub](https://github.com/lancedb/vectordb-recipes/tree/main/examples/parent_document_retriever) |
| Agentic RAG | This tutorial demonstrates how to build a RAG system where multiple AI agents collaborate to retrieve information and generate answers, leading to more robust and intelligent applications. | [Open in Colab](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/tutorials/Agentic_RAG/main.ipynb)<br>[View on GitHub](https://github.com/lancedb/vectordb-recipes/tree/main/tutorials/Agentic_RAG) |
| GraphRAG | Explores a hierarchical approach to RAG using knowledge graphs. This example shows how to build a graph-based index of your data, which can be used to perform more efficient and context-aware retrievals. | [Open in Colab](https://colab.research.google.com/github/lancedb/vectordb-recipes/blob/main/examples/Graphrag/main.ipynb)<br>[View on GitHub](https://github.com/lancedb/vectordb-recipes/tree/main/examples/Graphrag) |
